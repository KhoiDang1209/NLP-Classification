{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqgjOt7jVouA",
        "outputId": "6e87d0bb-e759-4ebe-ed89-71807bb408b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.2.0)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\n",
            "Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('train_set.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qHDmfejSFmKl",
        "outputId": "d61748ad-fb75-4926-e593-34ec2e8231e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  label_numeric\n",
              "0  100+ STT Né thính, Cap né thính hài hước, NÉT ...              7\n",
              "1  Top 111+ stt cuộc sống an nhiên, bình dị tự tạ...              7\n",
              "2  Top hạt giống hoa dễ trồng, nở quanh năm cho n...              7\n",
              "3  Chi tiết 3 cách nấu rau bò khai đơn giản mà th...              1\n",
              "4  Top 10 quạt cây hơi nước được ưa chuộng nhất h...              4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa64dedc-2aa3-4e3d-a647-48986c2c8f10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label_numeric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100+ STT Né thính, Cap né thính hài hước, NÉT ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Top 111+ stt cuộc sống an nhiên, bình dị tự tạ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Top hạt giống hoa dễ trồng, nở quanh năm cho n...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chi tiết 3 cách nấu rau bò khai đơn giản mà th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Top 10 quạt cây hơi nước được ưa chuộng nhất h...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa64dedc-2aa3-4e3d-a647-48986c2c8f10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa64dedc-2aa3-4e3d-a647-48986c2c8f10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa64dedc-2aa3-4e3d-a647-48986c2c8f10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0703480-bf71-4613-99ad-37a8a1aaf805\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0703480-bf71-4613-99ad-37a8a1aaf805')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0703480-bf71-4613-99ad-37a8a1aaf805 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 6657,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6652,\n        \"samples\": [\n          \"Top 10 s\\u1eefa t\\u1eafm cho nam l\\u01b0u h\\u01b0\\u01a1ng l\\u00e2u \\u0111\\u01b0\\u1ee3c y\\u00eau th\\u00edch\",\n          \"N\\u00e0ng M\\u01a1 l\\u00e0 ai? Hot girl m\\u1ea1ng v\\u00e0 nh\\u1eefng l\\u00f9m x\\u00f9m, tranh c\\u00e3i\",\n          \"C\\u00e1ch t\\u1eb7ng th\\u1ebb v\\u00e0ng trong Coin Master kh\\u00f4ng c\\u1ea7n k\\u1ebft b\\u1ea1n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_numeric\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTDU5EF2UvGZ",
        "outputId": "8c89cbdb-811a-4e3e-d987-dc851671346b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\n",
            "Train Loss: 1.9145, Train Acc: 33.24%\n",
            "Val Loss: 1.2526, Val Acc: 36.11%\n",
            "Epoch 2/30:\n",
            "Train Loss: 1.6557, Train Acc: 51.44%\n",
            "Val Loss: 0.7351, Val Acc: 65.09%\n",
            "Epoch 3/30:\n",
            "Train Loss: 1.3497, Train Acc: 65.11%\n",
            "Val Loss: 0.5124, Val Acc: 73.87%\n",
            "Epoch 4/30:\n",
            "Train Loss: 1.2037, Train Acc: 70.97%\n",
            "Val Loss: 0.4762, Val Acc: 76.43%\n",
            "Epoch 5/30:\n",
            "Train Loss: 1.0956, Train Acc: 75.53%\n",
            "Val Loss: 0.4497, Val Acc: 77.55%\n",
            "Epoch 6/30:\n",
            "Train Loss: 1.0199, Train Acc: 78.50%\n",
            "Val Loss: 0.3855, Val Acc: 80.71%\n",
            "Epoch 7/30:\n",
            "Train Loss: 0.9608, Train Acc: 80.85%\n",
            "Val Loss: 0.3806, Val Acc: 81.53%\n",
            "Epoch 8/30:\n",
            "Train Loss: 0.9147, Train Acc: 83.08%\n",
            "Val Loss: 0.4014, Val Acc: 81.76%\n",
            "Epoch 9/30:\n",
            "Train Loss: 0.8693, Train Acc: 85.20%\n",
            "Val Loss: 0.4154, Val Acc: 82.43%\n",
            "Epoch 10/30:\n",
            "Train Loss: 0.8412, Train Acc: 85.92%\n",
            "Val Loss: 0.3991, Val Acc: 83.11%\n",
            "Epoch 11/30:\n",
            "Train Loss: 0.8016, Train Acc: 87.94%\n",
            "Val Loss: 0.4027, Val Acc: 83.48%\n",
            "Epoch 12/30:\n",
            "Train Loss: 0.7645, Train Acc: 89.58%\n",
            "Val Loss: 0.3976, Val Acc: 83.86%\n",
            "Epoch 13/30:\n",
            "Train Loss: 0.7415, Train Acc: 90.33%\n",
            "Val Loss: 0.4260, Val Acc: 83.93%\n",
            "Epoch 14/30:\n",
            "Train Loss: 0.7151, Train Acc: 91.68%\n",
            "Val Loss: 0.4323, Val Acc: 84.31%\n",
            "Epoch 15/30:\n",
            "Train Loss: 0.6802, Train Acc: 92.77%\n",
            "Val Loss: 0.4195, Val Acc: 84.91%\n",
            "Epoch 16/30:\n",
            "Train Loss: 0.6690, Train Acc: 93.58%\n",
            "Val Loss: 0.4113, Val Acc: 85.14%\n",
            "Epoch 17/30:\n",
            "Train Loss: 0.6537, Train Acc: 94.05%\n",
            "Val Loss: 0.4326, Val Acc: 84.31%\n",
            "Epoch 18/30:\n",
            "Train Loss: 0.6353, Train Acc: 94.84%\n",
            "Val Loss: 0.4441, Val Acc: 84.23%\n",
            "Epoch 19/30:\n",
            "Train Loss: 0.6206, Train Acc: 95.25%\n",
            "Val Loss: 0.4509, Val Acc: 84.61%\n",
            "Epoch 20/30:\n",
            "Train Loss: 0.6036, Train Acc: 95.94%\n",
            "Val Loss: 0.4448, Val Acc: 84.31%\n",
            "Epoch 21/30:\n",
            "Train Loss: 0.5941, Train Acc: 96.21%\n",
            "Val Loss: 0.4687, Val Acc: 84.68%\n",
            "Epoch 22/30:\n",
            "Train Loss: 0.5896, Train Acc: 96.53%\n",
            "Val Loss: 0.4352, Val Acc: 85.21%\n",
            "Epoch 23/30:\n",
            "Train Loss: 0.5756, Train Acc: 97.28%\n",
            "Val Loss: 0.4506, Val Acc: 85.21%\n",
            "Epoch 24/30:\n",
            "Train Loss: 0.5707, Train Acc: 97.37%\n",
            "Val Loss: 0.4671, Val Acc: 84.98%\n",
            "Epoch 25/30:\n",
            "Train Loss: 0.5680, Train Acc: 97.56%\n",
            "Val Loss: 0.4560, Val Acc: 85.59%\n",
            "Epoch 26/30:\n",
            "Train Loss: 0.5630, Train Acc: 97.60%\n",
            "Val Loss: 0.4536, Val Acc: 85.44%\n",
            "Epoch 27/30:\n",
            "Train Loss: 0.5635, Train Acc: 97.78%\n",
            "Val Loss: 0.4493, Val Acc: 85.44%\n",
            "Epoch 28/30:\n",
            "Train Loss: 0.5608, Train Acc: 97.67%\n",
            "Val Loss: 0.4521, Val Acc: 85.59%\n",
            "Epoch 29/30:\n",
            "Train Loss: 0.5582, Train Acc: 98.03%\n",
            "Val Loss: 0.4517, Val Acc: 85.44%\n",
            "Epoch 30/30:\n",
            "Train Loss: 0.5588, Train Acc: 98.03%\n",
            "Val Loss: 0.4516, Val Acc: 85.44%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from underthesea import word_tokenize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import re\n",
        "import math\n",
        "\n",
        "# Định nghĩa cell GRU tùy chỉnh\n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Trọng số của update gate\n",
        "        self.W_z = nn.Linear(input_size, hidden_size)\n",
        "        self.U_z = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        # Trọng số của reset gate\n",
        "        self.W_r = nn.Linear(input_size, hidden_size)\n",
        "        self.U_r = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        # Trọng số của candidate hidden state\n",
        "        self.W_h = nn.Linear(input_size, hidden_size)\n",
        "        self.U_h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        # Update gate z_t\n",
        "        z_t = torch.sigmoid(self.W_z(x) + self.U_z(h_prev))\n",
        "\n",
        "        # Reset gate r_t\n",
        "        r_t = torch.sigmoid(self.W_r(x) + self.U_r(h_prev))\n",
        "\n",
        "        # Candidate hidden state h_hat_t\n",
        "        h_hat_t = torch.tanh(self.W_h(x) + self.U_h(r_t * h_prev))\n",
        "\n",
        "        # Final hidden state h_t\n",
        "        h_t = (1 - z_t) * h_prev + z_t * h_hat_t\n",
        "\n",
        "        return h_t\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "class RotaryPositionalEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_seq_len=200):\n",
        "        super().__init__()\n",
        "        # Ensure dim is even\n",
        "        if dim % 2 != 0:\n",
        "            raise ValueError(\"RotaryPositionalEmbedding dimension must be even\")\n",
        "        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        position = torch.arange(max_seq_len).float()\n",
        "        sinusoid_inp = torch.einsum(\"i,j->ij\", position, inv_freq)\n",
        "        self.register_buffer(\"sin\", sinusoid_inp.sin())\n",
        "        self.register_buffer(\"cos\", sinusoid_inp.cos())\n",
        "\n",
        "    def forward(self, x, seq_len):\n",
        "        # Apply RoPE to the last dimension\n",
        "        dim = x.shape[-1]\n",
        "        x1, x2 = x.chunk(2, dim=-1)\n",
        "\n",
        "        # Get sin and cos for the current sequence length\n",
        "        sin, cos = self.sin[:seq_len, :dim//2], self.cos[:seq_len, :dim//2]\n",
        "\n",
        "\n",
        "        num_leading_dims = x.ndim - 2\n",
        "        reshape_pattern = (1,) * num_leading_dims + (seq_len, dim // 2)\n",
        "        sin = sin.view(*reshape_pattern)\n",
        "        cos = cos.view(*reshape_pattern)\n",
        "\n",
        "        # Apply rotation\n",
        "        rotated_x = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1)\n",
        "\n",
        "        return rotated_x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads=4, max_seq_len=200):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_size // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.q_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.k_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.v_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.out_proj = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Add RoPE\n",
        "        self.rope = RotaryPositionalEmbedding(self.head_dim, max_seq_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Project queries, keys, and values\n",
        "        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Apply RoPE to queries and keys\n",
        "        q = self.rope(q, seq_len)\n",
        "        k = self.rope(k, seq_len)\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention to values\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        return self.out_proj(context)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers=2, dropout=0.5):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Rotary positional embedding\n",
        "        self.rope = RotaryPositionalEmbedding(embed_size)\n",
        "\n",
        "        # Multiple GRU layers\n",
        "        self.gru_layers = nn.ModuleList([\n",
        "            GRUCell(embed_size if i == 0 else hidden_size, hidden_size)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Bidirectional processing\n",
        "        self.gru_layers_reverse = nn.ModuleList([\n",
        "            GRUCell(embed_size if i == 0 else hidden_size, hidden_size)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norm1 = LayerNorm(hidden_size * 2)\n",
        "        self.layer_norm2 = LayerNorm(hidden_size * 2)\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attention = MultiHeadAttention(hidden_size * 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Additional fully connected layers with residual connections\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.fc2 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Label smoothing\n",
        "        self.label_smoothing = 0.1\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout1(self.embedding(x))\n",
        "        batch_size = x.size(0)\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        # Apply rotary positional embedding\n",
        "        embedded = self.rope(embedded, seq_len)\n",
        "\n",
        "        # Initialize hidden states for each layer\n",
        "        h_forward = [torch.zeros(batch_size, self.gru_layers[0].hidden_size, device=x.device)\n",
        "                    for _ in range(len(self.gru_layers))]\n",
        "        h_backward = [torch.zeros(batch_size, self.gru_layers[0].hidden_size, device=x.device)\n",
        "                     for _ in range(len(self.gru_layers))]\n",
        "\n",
        "        # Store all hidden states for attention\n",
        "        all_hidden_states = []\n",
        "\n",
        "        # Process sequence\n",
        "        for t in range(seq_len):\n",
        "            # Forward pass\n",
        "            x_t = embedded[:, t, :]\n",
        "            for layer_idx, gru in enumerate(self.gru_layers):\n",
        "                h_forward[layer_idx] = gru(x_t, h_forward[layer_idx])\n",
        "                x_t = h_forward[layer_idx]\n",
        "\n",
        "            # Backward pass\n",
        "            x_t_reverse = embedded[:, seq_len - 1 - t, :]\n",
        "            for layer_idx, gru in enumerate(self.gru_layers_reverse):\n",
        "                h_backward[layer_idx] = gru(x_t_reverse, h_backward[layer_idx])\n",
        "                x_t_reverse = h_backward[layer_idx]\n",
        "\n",
        "            # Concatenate forward and backward states\n",
        "            combined_h = torch.cat([h_forward[-1], h_backward[-1]], dim=1)\n",
        "            all_hidden_states.append(combined_h)\n",
        "\n",
        "        # Stack all hidden states\n",
        "        all_hidden_states = torch.stack(all_hidden_states, dim=1)\n",
        "\n",
        "        # Apply layer normalization\n",
        "        all_hidden_states = self.layer_norm1(all_hidden_states)\n",
        "\n",
        "        # Apply multi-head attention\n",
        "        attended = self.attention(all_hidden_states)\n",
        "        attended = self.layer_norm2(attended)\n",
        "\n",
        "        # Global average pooling\n",
        "        context_vector = torch.mean(attended, dim=1)\n",
        "\n",
        "        # Additional fully connected layers with residual connections\n",
        "        out = self.dropout2(context_vector)\n",
        "        residual = out\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout2(out)\n",
        "        out = out + residual\n",
        "\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, word2idx, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.word2idx = word2idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Convert text to sequence of indices\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        indices = [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n",
        "\n",
        "        # Pad or truncate sequence\n",
        "        if len(indices) < self.max_len:\n",
        "            indices = indices + [self.word2idx['<PAD>']] * (self.max_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:self.max_len]\n",
        "\n",
        "        return torch.tensor(indices), torch.tensor(label)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and extra spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    # Tokenize all texts\n",
        "    all_tokens = []\n",
        "    for text in texts:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        all_tokens.extend(tokens)\n",
        "\n",
        "    # Count token frequencies\n",
        "    token_counts = Counter(all_tokens)\n",
        "\n",
        "    # Create vocabulary\n",
        "    vocab = ['<PAD>', '<UNK>']  # Special tokens\n",
        "    vocab.extend([token for token, count in token_counts.items() if count >= min_freq])\n",
        "\n",
        "    # Create word to index mapping\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "    return vocab, word2idx\n",
        "\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    EMBED_SIZE = 300\n",
        "    HIDDEN_SIZE = 512\n",
        "    MAX_LEN = 200\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 30\n",
        "    LEARNING_RATE = 0.0003\n",
        "    WEIGHT_DECAY = 2e-4\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv('train_set.csv')\n",
        "    texts = df['title'].apply(preprocess_text).values\n",
        "    labels = df['label_numeric'].values\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Build vocabulary\n",
        "    vocab, word2idx = build_vocab(texts, min_freq=2)\n",
        "    vocab_size = len(vocab)\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    # Split data\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = TextDataset(train_texts, train_labels, word2idx, MAX_LEN)\n",
        "    val_dataset = TextDataset(val_texts, val_labels, word2idx, MAX_LEN)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GRUModel(\n",
        "        vocab_size=vocab_size,\n",
        "        embed_size=EMBED_SIZE,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        output_size=num_classes,\n",
        "        num_layers=2,\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = FocalLoss(alpha=1, gamma=2)  # Using Focal Loss\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        betas=(0.9, 0.999),\n",
        "        eps=1e-8\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler with warmup\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=LEARNING_RATE,\n",
        "        epochs=NUM_EPOCHS,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.1,\n",
        "        div_factor=25,\n",
        "        final_div_factor=1000\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    best_val_acc = 0.0\n",
        "    patience = 7\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Apply label smoothing\n",
        "            if model.training:\n",
        "                smooth_labels = torch.zeros_like(outputs).scatter_(1, labels.unsqueeze(1), 1)\n",
        "                smooth_labels = smooth_labels * (1 - model.label_smoothing) + model.label_smoothing / num_classes\n",
        "                loss = -(smooth_labels * torch.log_softmax(outputs, dim=1)).sum(dim=1).mean()\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{NUM_EPOCHS}:')\n",
        "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_gru_model.pth')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping triggered after {epoch + 1} epochs')\n",
        "                break\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1isX7s6hChuJ4GHkVwP80C9DZtbfv1FXl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d22vkq6DxiYo",
        "outputId": "0d1b5c64-3231-4cea-8206-29dd544fca31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1isX7s6hChuJ4GHkVwP80C9DZtbfv1FXl\n",
            "To: /content/test_set_public.csv\n",
            "\r  0% 0.00/99.5k [00:00<?, ?B/s]\r100% 99.5k/99.5k [00:00<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from underthesea import word_tokenize\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    all_tokens = []\n",
        "    for text in texts:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        all_tokens.extend(tokens)\n",
        "\n",
        "    token_counts = Counter(all_tokens)\n",
        "\n",
        "    vocab = ['<PAD>', '<UNK>']\n",
        "    vocab.extend([token for token, count in token_counts.items() if count >= min_freq])\n",
        "\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "    return vocab, word2idx\n",
        "\n",
        "def predict_sentence(model, sentence, word2idx, max_len=200, device='cuda'):\n",
        "    \"\"\"\n",
        "    Predict label for a single sentence using the trained GRU model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained GRU model\n",
        "    - sentence: Input sentence (string)\n",
        "    - word2idx: Word to index mapping dictionary\n",
        "    - max_len: Maximum sequence length\n",
        "    - device: Device to run inference on\n",
        "\n",
        "    Returns:\n",
        "    - predicted_label: Predicted label (integer)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    sentence = preprocess_text(sentence)\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "\n",
        "    indices = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
        "\n",
        "    if len(indices) < max_len:\n",
        "        indices = indices + [word2idx['<PAD>']] * (max_len - len(indices))\n",
        "    else:\n",
        "        indices = indices[:max_len]\n",
        "\n",
        "\n",
        "    input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    return predicted.item()\n",
        "\n",
        "# Load the test data\n",
        "test_df = pd.read_csv('test_set_public.csv')\n",
        "\n",
        "train_df = pd.read_csv('train_set.csv')\n",
        "train_texts = train_df['title'].apply(preprocess_text).values\n",
        "\n",
        "vocab, word2idx = build_vocab(train_texts, min_freq=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GRUModel(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_size=300,\n",
        "    hidden_size=512,\n",
        "    output_size=len(train_df['label_numeric'].unique()),\n",
        "    num_layers=2,\n",
        "    dropout=0.5\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('best_gru_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Make predictions\n",
        "test_df['label_numeric'] = test_df['title'].apply(\n",
        "    lambda x: predict_sentence(model, x, word2idx, max_len=200, device=device)\n",
        ")\n",
        "\n",
        "# Prepare submission file\n",
        "submission_df = test_df[['_id', 'label_numeric']].copy()\n",
        "submission_df.rename(columns={'_id': 'id'}, inplace=True)\n",
        "\n",
        "# Save predictions\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdBXJCdyx9ub",
        "outputId": "261aa688-d2fe-46a8-f4bd-9726c2ff720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    }
  ]
}